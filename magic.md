<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-Robust Classifier">
  <meta name="keywords" content="image-synthesis, model inversion, imagenet">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-Robust Classifier</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-Robust Classifier</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/mozhdeh-rouhsedaghat">Mozhdeh Rouhsedaghat</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/masoudmonajatipoor">Masoud Monajatipoor</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://mcl.usc.edu/people/cckuo/">C.-C. Jay Kuo</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://iacopomasi.github.io">Iacopo Masi </a><sup>3</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Southern California (USC), </span>
            <span class="author-block"><sup>2</sup>University of California Los Angeles (UCLA), </span>
            <span class="author-block"><sup>3</sup>Sapienza, University of Rome</span><br>
            <span class="author-block">The Thirty-Seventh Conference on Artificial Intelligence (AAAI) 2023</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2209.11549"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2209.11549"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src='static/images/header.png' />
      <h2 class="subtitle has-text-centered">
        <em>Multiple image manipulation tasks with a single method: </em><strong>MAGIC</strong> allows a diverse set of image synthesis tasks following the semantic of objects and scenes requiring only a single image, its segmentation mask, and a guide mask. In each pair, the left image is the input, and the right one is the manipulated image, guided by the mask shown on top. a) position control and copy/move manipulation by editing the guide mask; b) non-rigid shape control on scenes (repetitive). c) non-rigid shape control on objects such as animals (non-repetitive).
      </h2>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We offer a method for one-shot image synthesis that allows controlling manipulations of a single image by inverting a quasi-robust classifier equipped with strong regularizers. Our proposed method, entitled Magic, samples structured gradients from a pre-trained quasi-robust classifier to better preserve the input semantics while preserving its classification accuracy, thereby guaranteeing credibility in the synthesis. Unlike current methods that use complex primitives to supervise the process or use attention maps as a weak supervisory signal, Magic aggregates gradients over the input, driven by a guide binary mask that enforces a strong, spatial prior. Magic implements a series of manipulations with a single framework achieving shape and location control, intense non-rigid shape deformations, and copy/move operations in the presence of repeating objects and gives users firm control over the synthesis by requiring simply specifying binary guide masks. Our study and findings are supported by various qualitative comparisons with the state-of-the-art on the same images sampled from ImageNet and quantitative analysis using machine perception along with a user survey of 100+ participants that endorse our synthesis quality.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/fig_0.png" alt="method" height="550"/>
        <h2 class="subtitle has-text-centered">
          a) The binary mask y' is used as a guide; x' is inverted from x  latent code z, constrained with y' b) x' receives structured gradients from the main network to preserve the semantics of z; it receives gradients from a discriminator to match x's patch distribution. An ED is pre-trained to map x to y, we then introduce gradients from ED to guide x' shape/location constrained with y'. c) Gradients from ResNet-50---also used in IMAGINE---exhibit a sparse structure with activations around the borders; compared with a non-robust model, a quasi-robust model yields gradients with structure as eps increases.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/fig_1.png" alt="figure 1" height="250"/>
        <h2 class="subtitle has-text-centered">
          a) Singan and IMAGINE fail to capture the arrangement of parts of objects. Supervision with primitives may lead to better performance---DeepSim and our MAGIC). b) Even when IMAGINE uses supervision---right column---the synthesis is limited or requires the clip-art to match the image colors. c) Our MAGIC can handle a spectrum of deformations from mild to even intense, whereas DeepSim fails to generate unseen parts or to interpolate empty regions; d) on the contrary, DeepSim preserves the contour of objects better though it ``curves'' straight lines and shows artifacts when the mask provides no direct supervision.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/fig_2.png" alt="qualitative"/>
        <h2 class="subtitle has-text-centered">
          <b>Qualitative comparison.</b> DeepSim and MAGIC use the same guide masks y'. a) IMAGINE fails to perform position control and generates fragmented results. b) & c) & e) DeepSim cannot synthesize realistic objects when y' is extremely different from $\ysrc$ whereas MAGIC succeeds. d) The synthesized object by IMAGINE has an unrealistic texture while requiring more supervision for performing shape control, i.e., a color painting of the target image. f) IMAGINE generates samples similar to the input with no supervision, while  MAGIC enforces large variation using the guide masks. g) For shape control on complex scenes, MAGIC generates high-fidelity results while DeepSim synthesizes blurry and "curved" images.
       </h2>
     </div>
     <div class="item">
      <img src="static/images/fig_3.png" alt="repeating"/>
      <h2 class="subtitle has-text-centered">
      For each input, we fix the mask and start the synthesis from three different starting points x'. While observing the boundaries specified by the target mask y' and generating realistic images, MAGIC keeps specificity and generates diverse results.
      </h2>
    </div>
  </div>
</div>
</div>
</section>


<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper poster -->

      <h2 class="title">AAAI23 Poster</h2>

      <iframe  src="static/pdfs/poster.pdf" width="100%" height="550">
          </iframe>
        <!--/ Paper poster -->
      </div>
    </div>

  </section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{rouhsedaghat2023magic,
  author    = {Rouhsedaghat, Mozhdeh and Monajatipoor, Masoud and Kuo, C.-C. Jay  and Masi, Iacopo},
  title     = {MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-Robust Classifier},
  journal   = {The Thirty-Seventh Conference on Artificial Intelligence - AAAI},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://homes.cs.washington.edu/~kpar/nerfies/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
